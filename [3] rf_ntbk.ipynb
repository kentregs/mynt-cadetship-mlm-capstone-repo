{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "existing-voice",
   "metadata": {},
   "source": [
    "# Peforming model training using sklearn's RandomForestRegressor model\n",
    "\n",
    "In this notebook, the synthetic data generated in the synthetic_data_ntbk was ocne again imported and used to train sklearn's RandomForestRegressor model. the model is a meta estimator that fits a number of classifying decision trees on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting.\n",
    "\n",
    "Reference: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enormous-racing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superb-congress",
   "metadata": {},
   "source": [
    "### Import synthetic training and validation data from corresponding directory and verify data integrity\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "separate-niger",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = pd.read_csv('data/training_data.csv')\n",
    "validation_df = pd.read_csv('data/validation_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "funky-exchange",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 640 entries, 0 to 639\n",
      "Data columns (total 8 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       640 non-null    float64\n",
      " 1   1       640 non-null    float64\n",
      " 2   2       640 non-null    float64\n",
      " 3   3       640 non-null    float64\n",
      " 4   4       640 non-null    float64\n",
      " 5   5       640 non-null    float64\n",
      " 6   6       640 non-null    float64\n",
      " 7   target  640 non-null    float64\n",
      "dtypes: float64(8)\n",
      "memory usage: 40.1 KB\n"
     ]
    }
   ],
   "source": [
    "training_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ideal-arrest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 8 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       200 non-null    float64\n",
      " 1   1       200 non-null    float64\n",
      " 2   2       200 non-null    float64\n",
      " 3   3       200 non-null    float64\n",
      " 4   4       200 non-null    float64\n",
      " 5   5       200 non-null    float64\n",
      " 6   6       200 non-null    float64\n",
      " 7   target  200 non-null    float64\n",
      "dtypes: float64(8)\n",
      "memory usage: 12.6 KB\n"
     ]
    }
   ],
   "source": [
    "validation_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "isolated-dutch",
   "metadata": {},
   "source": [
    "## Model training and Hyperparameter tuning\n",
    "\n",
    "In an attempt to increase the accuracy of our prediction results, hyperparameter tuning was performed in this notebook using sklearn's RandomizedSearchCV.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "native-python",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_features': max_features,\n",
    "    'max_depth': max_depth,\n",
    "    'min_samples_split': min_samples_split,\n",
    "    'min_samples_leaf': min_samples_leaf,\n",
    "    'bootstrap': bootstrap\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "sporting-decrease",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestRegressor(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(\n",
    "    estimator=rf, \n",
    "    param_distributions=random_grid, \n",
    "    n_iter=100, \n",
    "    cv=3, \n",
    "    verbose=2, \n",
    "    random_state=42, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# train RandomForestRegressor using RandomizedSearchCV\n",
    "rf_random.fit(\n",
    "    training_df[['0', '1', '2', '3', '4', '5', '6']], \n",
    "    training_df['target']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "surface-senator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1600,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 90,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dense-visit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for evaluating a model\n",
    "def evaluate(model, features, labels):\n",
    "    predictions = model.predict(features)\n",
    "    mean_squared_error = np.mean((labels - predictions)**2)\n",
    "    score = model.score(features, labels)\n",
    "\n",
    "    print(f'\\nMSE = {mean_squared_error}')\n",
    "    print(f'Model accuracy (R^2 score) = {score * 100}\\n')\n",
    "    \n",
    "    return mean_squared_error, score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "awful-biodiversity",
   "metadata": {},
   "source": [
    "## Train and evaluate both base and tuned RandomForestRegressor models\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "opening-angola",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MSE = 3943.902885011237\n",
      "Model accuracy (R^2 score) = 75.40195760042964\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train base RandomForestRegressor\n",
    "base_model = RandomForestRegressor(random_state=0)\n",
    "base_model.fit(\n",
    "    training_df[['0', '1', '2', '3', '4', '5', '6']], \n",
    "    training_df['target']\n",
    ")\n",
    "\n",
    "# evaluate using validation data\n",
    "base_mse, base_accuracy = evaluate(\n",
    "    base_model, \n",
    "    validation_df[['0', '1', '2', '3', '4', '5', '6']], \n",
    "    validation_df['target']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "checked-finger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MSE = 3877.7746257594035\n",
      "Model accuracy (R^2 score) = 75.81439821377951\n",
      "\n",
      "Improvement of 0.55%.\n"
     ]
    }
   ],
   "source": [
    "best_random = rf_random.best_estimator_\n",
    "random_mse, random_accuracy = evaluate(\n",
    "    best_random, \n",
    "    validation_df[['0', '1', '2', '3', '4', '5', '6']], \n",
    "    validation_df['target']\n",
    ")\n",
    "\n",
    "print('Improvement of {:0.2f}%.'.format( 100 * (random_accuracy - base_accuracy) / base_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "champion-seating",
   "metadata": {},
   "source": [
    "From the generated results, the tuned model saw an improvement of 0.55%. As such, we will be pickling this model \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defensive-check",
   "metadata": {},
   "source": [
    "## Pickle tuned RandomForestRegressor model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "embedded-compound",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/capstone_rf_model.pkl']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save to file in the current working directory\n",
    "joblib_file = 'models/capstone_rf_model.pkl'\n",
    "joblib.dump(best_random, joblib_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-percentage",
   "metadata": {},
   "source": [
    "## Import the validation and evaluation csv files\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "improved-block",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import validation and evaluation csv files  \n",
    "valid_df = pd.read_csv('data/valid_data.csv')\n",
    "eval_df = pd.read_csv('data/evaluation_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forward-prediction",
   "metadata": {},
   "source": [
    "## Store all of the model performance results in the imported dataframes\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "alive-stranger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>MSE</th>\n",
       "      <th>r2_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>2568.494309</td>\n",
       "      <td>83.980353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>3877.774626</td>\n",
       "      <td>75.814398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               algorithm          MSE   r2_score\n",
       "0       LinearRegression  2568.494309  83.980353\n",
       "1  RandomForestRegressor  3877.774626  75.814398"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_data = {\n",
    "    'algorithm': 'RandomForestRegressor',\n",
    "    'MSE': random_mse,\n",
    "    'r2_score': random_accuracy*100\n",
    "}\n",
    "\n",
    "#append row to the dataframe\n",
    "eval_df = eval_df.append(rf_data, ignore_index=True)\n",
    "\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "grand-reducing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>lr_predictions</th>\n",
       "      <th>rf_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>223.013403</td>\n",
       "      <td>249.381526</td>\n",
       "      <td>184.263197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103.557634</td>\n",
       "      <td>50.058942</td>\n",
       "      <td>26.280123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>208.844585</td>\n",
       "      <td>189.456792</td>\n",
       "      <td>168.070799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-65.937306</td>\n",
       "      <td>-36.324588</td>\n",
       "      <td>40.217284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-37.186189</td>\n",
       "      <td>-57.440259</td>\n",
       "      <td>-37.501712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       actual  lr_predictions  rf_predictions\n",
       "0  223.013403      249.381526      184.263197\n",
       "1  103.557634       50.058942       26.280123\n",
       "2  208.844585      189.456792      168.070799\n",
       "3  -65.937306      -36.324588       40.217284\n",
       "4  -37.186189      -57.440259      -37.501712"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_predictions = best_random.predict(validation_df[['0', '1', '2', '3', '4', '5', '6']])\n",
    "\n",
    "valid_df['rf_predictions'] = rf_predictions\n",
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "significant-sucking",
   "metadata": {},
   "source": [
    "## Export model evaluation dataframes into csv files\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "interpreted-dodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export data \n",
    "valid_df.to_csv('data/valid_data.csv', index=False)\n",
    "eval_df.to_csv('data/evaluation_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
